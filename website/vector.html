<!DOCTYPE html>
<html lang="en-us">

<head>
  <link rel="icon" href="resources/heart.png"
  <meta charset="UTF-8">
  <title>ML  & Heart Disease</title>

 <!-- Bring in our bootstrap stylesheet -->

 
<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">

 <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
 <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
 <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>

 <link rel="stylesheet" href="style.css">
</head>

<body>
    <nav class="navbar navbar-expand-lg navbar-dark bg-primary">
      <img src="resources/beat.gif" height="42" width="42">
        <a class="navbar-brand" href="index.html">ML Heart</a>
        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarColor01" aria-controls="navbarColor01" aria-expanded="false" aria-label="Toggle navigation">
          <span class="navbar-toggler-icon"></span>
        </button>    
        
        <div class="collapse navbar-collapse" id="navbarColor01">
          <ul class="navbar-nav mr-auto">
            <li class="nav-item active">
              <a class="nav-link" href="index.html">Home</a>
            </li>
            <li class="nav-item">
                <a class="nav-link" href="etl.html">ETL on Data</a>
              </li>
            <li class="nav-item dropdown active">
                <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                  ML Models
                </a>
                <div class="dropdown-menu" aria-labelledby="navbarDropdown">
                  <a class="dropdown-item" href="forest.html">Random Forest</a>
                  <a class="dropdown-item" href="logistic.html">Logistic Regression </a>
                  <a class="dropdown-item" href="neural.html">Neural Net</a>
                  <a class="dropdown-item" href="knearest.html">K Nearest Neighbors</a>
                  <a class="dropdown-item active" href="vector.html">Support Vector Machine</a>
                </div>
              </li>

            <li class="nav-item">
              <a class="nav-link"href="analysis.html">Analysis</a>
            </li>
            <li class="nav-item">
              <a class="nav-link "href="credits.html">Credits</a>
            </li>
          </ul>
          </div>
        </nav>
  <div class="container">


  
      <!-- Row 1 -->
      <div class="row">
        <div class="col-12 col-sm-12 col-md-12">
            <div class="jumbotron">
                 <h1><strong>Support Vector Machine (SVM) Learning Algorithm</strong></h1>
                <center> <img src="resources/svm-cover.jpeg" height="250" width="400"></center> 
                 <p><strong>Introduction</strong></p>
                 <p>Support vector machine is a simple algorithm that every machine learning expert should have in his/her arsenal. Support vector machine is highly preferred by many as it produces significant accuracy with less computation power. Support Vector Machine, abbreviated as SVM can be used for both regression and classification tasks. But, it is widely used in classification objectives.
                 </p>
                 <p>The objective of the support vector machine algorithm is to find a hyperplane in an N-dimensional space(N â€” the number of features) that distinctly classifies the data points.
                 </p>
                <center> <img src="resources/SVM_image1.png" alt="image 1" width=200 height=200>
                 <img src="resources/SVM_Image2.png" alt="image 2" width =200 height =200></center>
                 <p>To separate the two classes of data points, there are many possible hyperplanes that could be chosen. Our objective is to find a plane that has the maximum margin, i.e the maximum distance between data points of both classes. Maximizing the margin distance provides some reinforcement so that future data points can be classified with more confidence.</p>
<p><strong>Hyperplanes and Support Vectors</strong>
  </p>
  <p>Hyperplanes are decision boundaries that help classify the data points. Data points falling on either side of the hyperplane can be attributed to different classes. Also, the dimension of the hyperplane depends upon the number of features. If the number of input features is 2, then the hyperplane is just a line. If the number of input features is 3, then the hyperplane becomes a two-dimensional plane. It becomes difficult to imagine when the number of features exceeds 3.
    <center><img src="resources/SVM_image3.png" alt="image 4" width=600 height=300></center>
  </p>
  <p>Support vectors are data points that are closer to the hyperplane and influence the position and orientation of the hyperplane. Using these support vectors, we maximize the margin of the classifier. Deleting the support vectors will change the position of the hyperplane. These are the points that help us build our SVM.</p>
  <p><strong>&nbsp;</strong></p>
  <p><strong>&nbsp;</strong></p>
  <p><strong>Implementation on the Heart Disease dataset</strong></p>
  <p>The key advantage for the Heart Disease dataset is that SVM is effective for high dimensional spaces. &nbsp;The data set has 13 features (5 variable and 8 categorical). &nbsp;Once the categorical data is reformatted for binary there are 28 features.</p>
  <p>&nbsp;</p>
  <p>Validation curves were used to visualize and ultimately select the input parameters to maximize the accuracy of the model. &nbsp;A linear kernel was selected and a gamma value of 0.1 to maximize the cross-validation score. &nbsp;The decision function type was irrelevant.
    <center><img src="resources/SVM_image4.png" alt="image3" width = 600 height = 400></center>
  </p>
  <p><center><img src="resources/SVM_image_5.png" alt="image 5" width = 600 height = 400 ></center>
    </p>
    <p>Next, the size of the training set was evaluated using a learning curve. &nbsp;It was confirmed that the default train/test/split method from scikit-learn splits training (220) and testing (74) data sets where the scores converge.</p>
   <center><img src="resources/SVM_image6.png" alt="image 6" width = 600 height = 400></center>
    <p>Running the test data set, the following classification report results:
   <center><img src="resources/SVM_table1.png" alt="table 1"></center>
    </p>
    <p>Running this data set on the pre-set train/test split resulted in the following:</p>
<p>&nbsp;</p>
<ul>
  <li>82% of the time Heart Disease or Healthy was predicted correctly (Accuracy)</li>
  <li>83% of Heart Disease predictions were Heart Disease (Precision)</li>
  <li>82% of Heart Disease samples were correctly predicted (Recall)</li>
  <li>Overall 82% harmonic average of precision and recall (F1 Score)</li>
</ul>

        </div>
    </div>
      </div>
      </div>
</body>
</html>