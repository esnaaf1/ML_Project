<!DOCTYPE html>
<html lang="en-us">

<head>
  <link rel="icon" href="resources/heart.png"
  <meta charset="UTF-8">
  <title>ML  & Heart Disease</title>

 <!-- Bring in our bootstrap stylesheet -->

 
<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">

 <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
 <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
 <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>

 <link rel="stylesheet" href="style.css">
</head>

<body>
    <nav class="navbar navbar-expand-lg navbar-dark bg-primary">
      <img src="resources/beat.gif" height="42" width="42">
        <a class="navbar-brand" href="index.html">ML Heart</a>
        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarColor01" aria-controls="navbarColor01" aria-expanded="false" aria-label="Toggle navigation">
          <span class="navbar-toggler-icon"></span>
        </button>       
      
        <div class="collapse navbar-collapse" id="navbarColor01">
          <ul class="navbar-nav mr-auto">
            <li class="nav-item active">
              <a class="nav-link" href="index.html">Home</a>
            </li>
            <li class="nav-item">
                <a class="nav-link" href="etl.html">ETL on Data</a>
              </li>
            <li class="nav-item dropdown active">
                <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                  ML Models
                </a>
                <div class="dropdown-menu" aria-labelledby="navbarDropdown">
                  <a class="dropdown-item" href="forest.html">Random Forest</a>
                  <a class="dropdown-item" href="logistic.html">Logistic Regression </a>
                  <a class="dropdown-item" href="neural.html">Neural Net</a>
                  <a class="dropdown-item active" href="knearest.html">K Nearest Neighbors</a>
                  <a class="dropdown-item" href="vector.html">Support Vector Machine</a>
                </div>
              </li>

            <li class="nav-item">
              <a class="nav-link"href="analysis.html">Analysis</a>
            </li>
          </ul>
          </div>
        </nav>
  <div class="container">


  
      <!-- Row 1 -->
      <div class="row">
        <div class="col-12 col-sm-12 col-md-12">
            <div class="jumbotron">
                 <h1>K-Nearest Neighbor (KNN) Machine Learning Algorithm</h1>
                 <p> 
                <u>Background:</u>   KNN algorithm is a simple, easy to implement supervised machine learning algorithm that can be used to solve both regression and classification problems.   The KNN algorithm assumes that similar things are near each other.  <br> <br>
            <u>How KNN algorithm works:</u>
                    <ol>
                        <li>Load the data</li>
                        <li>Initialize K to chosen number of neighbors</li>
                        <li>For each instance in the data:</li>
                    <p>A. Calculate the distance between the query example and the current example from the data.</p>
                    <p>B. Add the distance and the index of the example to an ordered collection</p>
                    <li>Sort the ordered collection of distances and indices from smallest to largest (in ascending order) by the distances</li>
                    <li>Pick the first K entries from the sorted collection</li>
                    <li>Get the labels of the selected K entries</li>
                    <li>If regression, return the mean of the K labels</li>
                    <li>If classification, return the mode of the K labels</li></ol></p>
                    <br> <br>
                   <p><u>Implementation:<br></u>   
                    We used KNN as a classifier algorithm, and used the heart disease dataset found in the <a href='https://archive.ics.uci.edu/ml/datasets/Heart+Disease'>UCI Machine Learning website </a><br><br>
                    After splitting the heart disease data into train and test sets, the data was scaled and encoded. A KNN classifier model was setup, we looped through a list of K values to determine the best accuracy score.<br><br>
                    The results showed that the K=5 results in the best score for both train and test data.<br>
                   <center><img src="resources/k5which.jpg" alt="K nearest results"></center>       
         </p>
         <p>The overall accuracy of the model was 0.784.</p>
<p><u>Algorithm modification and tuning:</u> Given the limited data samples, K-Fold Cross-Validation was used to resample and evaluate the KNN model. Cross-validation is primary used in machine learning estimate the skills of the model on unseen data.The general procedure is as follows:</p>
<ol>
  <li>Shuffle the dataset randomly</li>
  <li>Split the dataset into k groups</li>
  <li>For each unique group
    <ol>
      <p>A. Take the group as a hold out or test data</p>
      <p>B. Take the remaining groups as a training data set</p>
      <p>C. Fit a model on the training set and evaluate it on the test set</p>
      <p>D. Retain the evaluation score and discard the model</p>
    </ol>
  </li>
  <li>Summarize the skill of the model using the sample of model evaluation scores</li>
</ol>
<p>When usingK-Fold Cross-validation procedure, it is important to note that each observation in the dataset is assigned to an individual group and stays in that group for the duration of the procedure. This means that each sample is given the opportunity to be used in the hold out set 1 time and used to train the model k-1 times.K values [1,3,5,7,9.11,13,15,17,19,21], were used in this procedure.</p>
<p>In addition, GridSearchCV along with cross-validation was used to evaluate the model across various parameters.</p>
<p>The graph below shows mean accuracy across the different k values.</p>
 <center> <img src="resources/accuracy.jpg"></center>
</p>
<p><u>Conclusion:</u>   KNN is very simple to implement and robust with regards to the search space; for instance, the classes do not have to be linearly separable.There are only two parameters to tune (k and distance metric.). The main disadvantage of the algorithm is that it is expensive testing of each new observation, due to the need to compute its distance from all known observation which becomes problematic with a dataset with a large number of features.</p>
        </div>
    </div>
      </div>
      </div>
</body>
</html>