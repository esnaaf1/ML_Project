<!DOCTYPE html>
<!DOCTYPE html>
<html lang="en-us">

<head>
  <link rel="icon" href="resources/heart.png"
  <meta charset="UTF-8">
  <title>ML  & Heart Disease</title>

 <!-- Bring in our bootstrap stylesheet -->

 
<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">

 <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
 <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
 <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>

 <link rel="stylesheet" href="style.css">
</head>

<body>
    <nav class="navbar navbar-expand-lg navbar-dark bg-primary">
      <img src="resources/beat.gif" height="42" width="42">
        <a class="navbar-brand" href="index.html">ML Heart</a>
        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarColor01" aria-controls="navbarColor01" aria-expanded="false" aria-label="Toggle navigation">
          <span class="navbar-toggler-icon"></span>
        </button>        
      
        <div class="collapse navbar-collapse" id="navbarColor01">
          <ul class="navbar-nav mr-auto">
            <li class="nav-item active">
              <a class="nav-link" href="index.html">Home</a>
            </li>
            <li class="nav-item">
                <a class="nav-link" href="etl.html">ETL on Data</a>
              </li>
            <li class="nav-item dropdown">
                <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                  ML Models
                </a>
                <div class="dropdown-menu" aria-labelledby="navbarDropdown">
                  <a class="dropdown-item" href="forest.html">Random Forest</a>
                  <a class="dropdown-item" href="logistic.html">Logistic Regression </a>
                  <a class="dropdown-item" href="neural.html">Neural Net</a>
                  <a class="dropdown-item" href="knearest.html">K Nearest Neighbors</a>
                  <a class="dropdown-item" href="vector.html">Support Vector Machine</a>
                </div>
              </li>

            <li class="nav-item">
              <a class="nav-link active"href="analysis.html">Analysis</a>
            </li>
          </ul>
          </div>
        </nav>
  <div class="container">


  
      <!-- Row 1 -->
      <div class="row">
        <div class="col-12 col-sm-12 col-md-12">
            <div class="jumbotron">
                 <h1><strong>Comparative Model Analysis</strong></h1>
                 <p><strong>Comparison</strong></p>
                 <p><u>Approach</u></p>
                 <p>The initial approach was to perform ETL on the heart disease data set and split the data using SciKit-Learn into a single train and test data set. &nbsp; This split data was then saved to csv files for each model architecture to be built and optimized. Only one version of the split train data was used to optimized the parameters of the models. By holding the train and test data split constant, it was believed that comparison of the five models would be more equivalent.</p>
                 <p>After reviewing false predictions across several models, it was observed that the majority of the false predictions were the same. Thinking through the results, it made sense that some samples may be harder to classify (potentially based on the train data) and therefore multiple models would falsely label the same data points. &nbsp;Based on this observation, to help understand the general performance of the different models, the team decided to split the full data set over multiple iterations and calculate the precision and accuracy of the models against different samplings of the test data.</p>
                 <p>Finally, the team decided to create two voting models. &nbsp;The first was a majority vote where if three or more models predicted heart disease then the “majority prediction” would vote heart disease. Otherwise, it would be given an output of healthy. &nbsp;The second model was a conservative model based on the desire to overpredict heart disease rather than underpredict it. &nbsp;This model predicted heart disease if a single model predicted it otherwise it requires a unanimous vote to predict healthy.</p>
                 <p><u>Models</u></p>
                 <ul>
                   <li>Random Forest (RF)</li>
                   <li>Logistic Regression (LR)</li>
                   <li>Support Vector Machines (SVM)</li>
                   <li>K Nearest Neighbor (KNN)</li>
                   <li>Neural Network (NN)</li>
                   <li>Majority Vote (Majority)</li>
                   <li>Conservative Vote (Conservative)</li>
                 </ul>
                 <p><u>Metrics</u></p>
                 <p><strong>SciKit-Learn model score</strong> – obtained from each model</p>
                 <p><strong>Confusion Matrix&nbsp;</strong>– Our goal was to minimize False Negatives.</p>
                 <table border="0" cellpadding="0" cellspacing="0" width="473">
                   <tbody>
                     <tr>
                       <td valign="bottom" width="19.661733615221987%">
                         <p>N - Total Observations</p>
                       </td>
                       <td valign="bottom" width="25.158562367864693%">
                         <p>&nbsp;</p>
                       </td>
                       <td colspan="2" width="55.17970401691332%">
                         <p><strong>Prediction</strong></p>
                       </td>
                     </tr>
                     <tr>
                       <td valign="bottom" width="19.661733615221987%">
                         <p>&nbsp;</p>
                       </td>
                       <td valign="bottom" width="25.158562367864693%">
                         <p>&nbsp;</p>
                       </td>
                       <td width="26.6384778012685%">
                         <p>Heart Disease</p>
                       </td>
                       <td width="28.54122621564482%">
                         <p>Healthy</p>
                       </td>
                     </tr>
                     <tr>
                       <td rowspan="2" width="19.661733615221987%">
                         <p><strong>Actual</strong></p>
                       </td>
                       <td width="25.158562367864693%">
                         <p>Heart Disease</p>
                       </td>
                       <td width="26.6384778012685%">
                         <p><strong>True Positive (TP)</strong></p>
                       </td>
                       <td width="28.54122621564482%">
                         <p><strong>False Negative (FN)</strong></p>
                       </td>
                     </tr>
                     <tr>
                       <td width="31.31578947368421%">
                         <p>Healthy</p>
                       </td>
                       <td width="33.1578947368421%">
                         <p><strong>False Positive (FP)</strong></p>
                       </td>
                       <td width="35.526315789473685%">
                         <p><strong>True Negative (TN)</strong></p>
                       </td>
                     </tr>
                     <tr>
                       <td valign="bottom" width="19.661733615221987%">
                         <p>&nbsp;</p>
                       </td>
                       <td valign="bottom" width="25.158562367864693%">
                         <p>&nbsp;</p>
                       </td>
                       <td valign="bottom" width="26.6384778012685%">
                         <p>&nbsp;</p>
                       </td>
                       <td valign="bottom" width="28.54122621564482%">
                         <p>&nbsp;</p>
                       </td>
                     </tr>
                     <tr>
                       <td valign="top" width="19.661733615221987%">
                         <p><strong>Accuracy</strong></p>
                       </td>
                       <td colspan="3" valign="top" width="80.33826638477801%">
                         <p>How often were samples classified correctly?
                           <br><strong><em>(TP + TN) / N</em></strong></p>
                       </td>
                     </tr>
                     <tr>
                       <td valign="top" width="19.661733615221987%">
                         <p><strong>Precision</strong></p>
                       </td>
                       <td colspan="3" valign="top" width="80.33826638477801%">
                         <p>Of all the samples classified as Heart Disease, how many are heart disease? &nbsp;<strong><em>TP / (TP + FP)</em></strong></p>
                       </td>
                     </tr>
                     <tr>
                       <td valign="top" width="19.661733615221987%">
                         <p><strong>Recall</strong></p>
                       </td>
                       <td colspan="3" valign="top" width="80.33826638477801%">
                         <p>Of all the actual heart disease samples, how many were classified as heart disease? <strong><em>&nbsp;TP / (TP + FN)</em></strong></p>
                       </td>
                     </tr>
                     <tr>
                       <td valign="top" width="19.661733615221987%">
                         <p><strong>F1 Score</strong></p>
                       </td>
                       <td colspan="3" valign="top" width="80.33826638477801%">
                         <p>Harmonic average of precision and recall where 1 is perfect and 0 is worst. <strong><em>2 * ((Precision * Recall)/(Precision + Recall))</em></strong></p>
                       </td>
                     </tr>
                   </tbody>
                 </table>
                 <p>Data was split a number of times to generate a population of the metrics above to understand the general accuracy and precision of each models.</p>
                 <p><u>Comparisons</u></p>
                 <p>For each metric above:</p>
                 <ul>
                   <li>A one-way ANOVA was applied to look for statistical significance in the means of the confusion matrix metrics between the different models.</li>
                   <li>A box-whisker plot was created to visualize population of the metrics for each mode.</li>
                 </ul>
                 <p><u>Observations</u></p>
                 <ol>
                   <li>Running minimal iterations (such as 5) of the split test data did not always show a difference between models for each metric. However, increasing the number of iterations (like to 500) increased the confidence and often demonstrated statistical differences between the models. Ultimately, the final number of iterations used for the analysis was 50, because it showed statistical difference between the models without repeating similar splits between the test data.</li>
                   <li>The SciKit-Learn model scores show Random Forest has the highest accuracy with Neural Network coming in second. &nbsp;However, when reviewing the confusion matrix metrics, we observed the following:
                     <ol>
                       <li>Highest Accuracy – Neural Network</li>
                       <li>Highest Precision – Random Forest then Neural Network 2nd</li>
                       <li>Highest Recall – Conservative Vote then Neural Network 2nd</li>
                       <li>Highest F1 Score – Neural Network</li>
                     </ol>
                   </li>
                 </ol>
                 <p><u>Conclusions</u></p>
                 <p>Random Forest was the most precise at predicting heart disease, but also underpredicted it overall (see Recall results). &nbsp;Because we prefer to over predict heart disease to ensure no sick patients go undiagnosed, we held a bias toward recall in our selection. The Conservative Vote, as expected, outperformed all models in Recall, but otherwise did not. The Neural Network outperformed or was a close second in all metrics.</p>
                 <p><u>ANOVA &amp; Histogram Samples</u></p>
                 <p>50 Iterations</p>
                 <center><img src="resources/Compare-image1.png"></center>
                 <p>

                 </p>
                 <center><img src="resources/Compare-image2.png"></center>
                 <p>

                 </p>
                 <center><img src="resources/Compare-image3.png"></center>
                 <p>
                   
                 </p>

        </div>
    </div>
      </div>
      </div>
</body>
</html>